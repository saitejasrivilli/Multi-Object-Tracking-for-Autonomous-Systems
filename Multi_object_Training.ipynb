{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing Packages"
      ],
      "metadata": {
        "id": "nCnpBcw1R6i9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1U1FPviR5Wi"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"üì¶ Installing packages...\")\n",
        "import subprocess\n",
        "import sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"ultralytics\", \"opencv-python-headless\", \"filterpy\",\n",
        "                      \"scipy\", \"numpy\", \"matplotlib\"])\n",
        "print(\"‚úÖ Packages installed!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "-k6JCf7yR-Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict, deque\n",
        "import os\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "os.makedirs('output', exist_ok=True)\n",
        "print(\"‚úÖ Libraries imported!\\n\")"
      ],
      "metadata": {
        "id": "dXhrXgCiR_cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kalman Box Tracker"
      ],
      "metadata": {
        "id": "BUEM63RrSBld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KalmanBoxTracker:\n",
        "    \"\"\"Kalman Filter for tracking bounding boxes.\"\"\"\n",
        "    count = 0\n",
        "\n",
        "    def __init__(self, bbox):\n",
        "        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n",
        "        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],\n",
        "                              [0,0,0,1,0,0,0],[0,0,0,0,1,0,0],[0,0,0,0,0,1,0],\n",
        "                              [0,0,0,0,0,0,1]])\n",
        "        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],\n",
        "                              [0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
        "        self.kf.R[2:, 2:] *= 10.0\n",
        "        self.kf.P[4:, 4:] *= 1000.0\n",
        "        self.kf.P *= 10.0\n",
        "        self.kf.Q[-1, -1] *= 0.01\n",
        "        self.kf.Q[4:, 4:] *= 0.01\n",
        "        self.kf.x[:4] = self.convert_bbox_to_z(bbox)\n",
        "        self.time_since_update = 0\n",
        "        self.id = KalmanBoxTracker.count\n",
        "        KalmanBoxTracker.count += 1\n",
        "        self.history = []\n",
        "        self.hits = 0\n",
        "        self.hit_streak = 0\n",
        "        self.age = 0\n",
        "\n",
        "    def update(self, bbox):\n",
        "        self.time_since_update = 0\n",
        "        self.history = []\n",
        "        self.hits += 1\n",
        "        self.hit_streak += 1\n",
        "        self.kf.update(self.convert_bbox_to_z(bbox))\n",
        "\n",
        "    def predict(self):\n",
        "        if self.kf.x[6] + self.kf.x[2] <= 0:\n",
        "            self.kf.x[6] *= 0.0\n",
        "        self.kf.predict()\n",
        "        self.age += 1\n",
        "        if self.time_since_update > 0:\n",
        "            self.hit_streak = 0\n",
        "        self.time_since_update += 1\n",
        "        self.history.append(self.convert_x_to_bbox(self.kf.x))\n",
        "        return self.history[-1]\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.convert_x_to_bbox(self.kf.x)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_bbox_to_z(bbox):\n",
        "        w = bbox[2] - bbox[0]\n",
        "        h = bbox[3] - bbox[1]\n",
        "        x = bbox[0] + w / 2.0\n",
        "        y = bbox[1] + h / 2.0\n",
        "        s = w * h\n",
        "        r = w / float(h)\n",
        "        return np.array([x, y, s, r]).reshape((4, 1))\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_x_to_bbox(x, score=None):\n",
        "        w = np.sqrt(x[2] * x[3])\n",
        "        h = x[2] / w\n",
        "        if score is None:\n",
        "            return np.array([x[0] - w/2., x[1] - h/2., x[0] + w/2., x[1] + h/2.]).reshape((1, 4))\n",
        "        else:\n",
        "            return np.array([x[0] - w/2., x[1] - h/2., x[0] + w/2., x[1] + h/2., score]).reshape((1, 5))\n",
        "\n",
        "print(\"‚úÖ Kalman Box Tracker defined\\n\")"
      ],
      "metadata": {
        "id": "WcDnRd16SDRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define IoU and association"
      ],
      "metadata": {
        "id": "LBclJPC-SFhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_batch(bb_test, bb_gt):\n",
        "    bb_gt = np.expand_dims(bb_gt, 0)\n",
        "    bb_test = np.expand_dims(bb_test, 1)\n",
        "    xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
        "    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
        "    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
        "    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
        "    w = np.maximum(0., xx2 - xx1)\n",
        "    h = np.maximum(0., yy2 - yy1)\n",
        "    intersection = w * h\n",
        "    area_test = (bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])\n",
        "    area_gt = (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1])\n",
        "    union = area_test + area_gt - intersection\n",
        "    return intersection / union\n",
        "\n",
        "def associate_detections_to_trackers(detections, trackers, iou_threshold=0.3):\n",
        "    if len(trackers) == 0:\n",
        "        return np.empty((0, 2), dtype=int), np.arange(len(detections)), np.empty((0, 5), dtype=int)\n",
        "    iou_matrix = iou_batch(detections, trackers)\n",
        "    if min(iou_matrix.shape) > 0:\n",
        "        a = (iou_matrix > iou_threshold).astype(np.int32)\n",
        "        if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
        "            matched_indices = np.stack(np.where(a), axis=1)\n",
        "        else:\n",
        "            matched_indices = linear_sum_assignment(-iou_matrix)\n",
        "            matched_indices = np.array(list(zip(*matched_indices)))\n",
        "    else:\n",
        "        matched_indices = np.empty(shape=(0, 2))\n",
        "    unmatched_detections = []\n",
        "    for d, det in enumerate(detections):\n",
        "        if d not in matched_indices[:, 0]:\n",
        "            unmatched_detections.append(d)\n",
        "    unmatched_trackers = []\n",
        "    for t, trk in enumerate(trackers):\n",
        "        if t not in matched_indices[:, 1]:\n",
        "            unmatched_trackers.append(t)\n",
        "    matches = []\n",
        "    for m in matched_indices:\n",
        "        if iou_matrix[m[0], m[1]] < iou_threshold:\n",
        "            unmatched_detections.append(m[0])\n",
        "            unmatched_trackers.append(m[1])\n",
        "        else:\n",
        "            matches.append(m.reshape(1, 2))\n",
        "    if len(matches) == 0:\n",
        "        matches = np.empty((0, 2), dtype=int)\n",
        "    else:\n",
        "        matches = np.concatenate(matches, axis=0)\n",
        "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
        "\n",
        "print(\"‚úÖ Association functions defined\\n\")"
      ],
      "metadata": {
        "id": "PaoU-gqRSIG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep SORT"
      ],
      "metadata": {
        "id": "Kd7BRq-ESK0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepSORT:\n",
        "    def __init__(self, max_age=30, min_hits=3, iou_threshold=0.3):\n",
        "        self.max_age = max_age\n",
        "        self.min_hits = min_hits\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.trackers = []\n",
        "        self.frame_count = 0\n",
        "        self.trajectories = defaultdict(lambda: deque(maxlen=30))\n",
        "\n",
        "    def update(self, detections):\n",
        "        self.frame_count += 1\n",
        "        trks = np.zeros((len(self.trackers), 5))\n",
        "        to_del = []\n",
        "        for t, trk in enumerate(trks):\n",
        "            pos = self.trackers[t].predict()[0]\n",
        "            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
        "            if np.any(np.isnan(pos)):\n",
        "                to_del.append(t)\n",
        "        trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
        "        for t in reversed(to_del):\n",
        "            self.trackers.pop(t)\n",
        "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(\n",
        "            detections, trks, self.iou_threshold)\n",
        "        for m in matched:\n",
        "            self.trackers[m[1]].update(detections[m[0], :])\n",
        "        for i in unmatched_dets:\n",
        "            trk = KalmanBoxTracker(detections[i, :])\n",
        "            self.trackers.append(trk)\n",
        "        ret = []\n",
        "        i = len(self.trackers)\n",
        "        for trk in reversed(self.trackers):\n",
        "            d = trk.get_state()[0]\n",
        "            if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
        "                ret.append(np.concatenate((d, [trk.id + 1])).reshape(1, -1))\n",
        "                center = ((d[0] + d[2]) / 2, (d[1] + d[3]) / 2)\n",
        "                self.trajectories[trk.id].append(center)\n",
        "            i -= 1\n",
        "            if trk.time_since_update > self.max_age:\n",
        "                self.trackers.pop(i)\n",
        "        if len(ret) > 0:\n",
        "            return np.concatenate(ret)\n",
        "        return np.empty((0, 5))\n",
        "\n",
        "    def predict_trajectory(self, track_id, num_frames=10):\n",
        "        for tracker in self.trackers:\n",
        "            if tracker.id == track_id:\n",
        "                predictions = []\n",
        "                saved_x = tracker.kf.x.copy()\n",
        "                saved_P = tracker.kf.P.copy()\n",
        "                for _ in range(num_frames):\n",
        "                    tracker.kf.predict()\n",
        "                    pred_box = KalmanBoxTracker.convert_x_to_bbox(tracker.kf.x)[0]\n",
        "                    center = ((pred_box[0] + pred_box[2]) / 2, (pred_box[1] + pred_box[3]) / 2)\n",
        "                    predictions.append(center)\n",
        "                tracker.kf.x = saved_x\n",
        "                tracker.kf.P = saved_P\n",
        "                return predictions\n",
        "        return []\n",
        "\n",
        "print(\"‚úÖ Deep SORT tracker defined\\n\")"
      ],
      "metadata": {
        "id": "g9jc6qxfSLct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YoLo"
      ],
      "metadata": {
        "id": "u1WSxmd8SN9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_model = YOLO('yolov8n.pt')\n",
        "COLORS = np.random.randint(0, 255, size=(200, 3), dtype=np.uint8)\n",
        "print(\"‚úÖ YOLO model loaded!\\n\")"
      ],
      "metadata": {
        "id": "7dA1YwQsSPIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "id": "Q0QerWWXSSdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_boxes_and_trajectories(frame, tracked_objects, tracker, show_predictions=True):\n",
        "    for track in tracked_objects:\n",
        "        x1, y1, x2, y2, track_id = track\n",
        "        track_id = int(track_id)\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        color = COLORS[track_id % len(COLORS)].tolist()\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "        label = f'ID: {track_id}'\n",
        "        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "        cv2.rectangle(frame, (x1, y1 - label_h - 10), (x1 + label_w, y1), color, -1)\n",
        "        cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "        if track_id in tracker.trajectories:\n",
        "            points = list(tracker.trajectories[track_id])\n",
        "            for i in range(1, len(points)):\n",
        "                if points[i - 1] is None or points[i] is None:\n",
        "                    continue\n",
        "                thickness = int(np.sqrt(64 / float(i + 1)) * 1.5)\n",
        "                cv2.line(frame, (int(points[i-1][0]), int(points[i-1][1])),\n",
        "                        (int(points[i][0]), int(points[i][1])), color, thickness)\n",
        "        if show_predictions:\n",
        "            predictions = tracker.predict_trajectory(track_id - 1, num_frames=10)\n",
        "            if len(predictions) > 0:\n",
        "                for i in range(1, len(predictions)):\n",
        "                    cv2.line(frame, (int(predictions[i-1][0]), int(predictions[i-1][1])),\n",
        "                            (int(predictions[i][0]), int(predictions[i][1])), color, 2, lineType=cv2.LINE_AA)\n",
        "                cv2.circle(frame, (int(predictions[-1][0]), int(predictions[-1][1])), 5, color, -1)\n",
        "    return frame\n",
        "\n",
        "print(\"‚úÖ Visualization function defined\\n\")"
      ],
      "metadata": {
        "id": "ZxfJ0ywbSTFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing Function"
      ],
      "metadata": {
        "id": "3FXcZpxUSVfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path, output_path='output/tracked_video.mp4',\n",
        "                  conf_threshold=0.4, max_frames=300, show_predictions=True):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ùå Error: Could not open video {video_path}\")\n",
        "        return None\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(f\"üìπ Video info: {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "    tracker = DeepSORT(max_age=30, min_hits=3, iou_threshold=0.3)\n",
        "    frame_count = 0\n",
        "    total_detections = 0\n",
        "    processing_times = []\n",
        "    print(f\"üöÄ Processing video (max {max_frames} frames)...\\n\")\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if max_frames and frame_count >= max_frames:\n",
        "            break\n",
        "        start_time = time.time()\n",
        "        results = yolo_model(frame, conf=conf_threshold, verbose=False)\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "                cls = int(box.cls[0])\n",
        "                if cls in [0, 1, 2, 3, 5, 7]:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                    conf = float(box.conf[0])\n",
        "                    detections.append([x1, y1, x2, y2, conf])\n",
        "        detections = np.array(detections) if len(detections) > 0 else np.empty((0, 5))\n",
        "        tracked_objects = tracker.update(detections)\n",
        "        frame = draw_boxes_and_trajectories(frame, tracked_objects, tracker, show_predictions)\n",
        "        info_text = f\"Frame: {frame_count + 1} | Objects: {len(tracked_objects)} | FPS: {1 / (time.time() - start_time):.1f}\"\n",
        "        cv2.putText(frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        out.write(frame)\n",
        "        processing_times.append(time.time() - start_time)\n",
        "        total_detections += len(tracked_objects)\n",
        "        frame_count += 1\n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"   ‚úì Processed {frame_count} frames...\")\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    avg_fps = 1 / np.mean(processing_times)\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"‚úÖ Processing complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  Frames processed: {frame_count}\")\n",
        "    print(f\"  Average FPS: {avg_fps:.2f}\")\n",
        "    print(f\"  Total detections: {total_detections}\")\n",
        "    print(f\"  Output saved to: {output_path}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    return output_path\n",
        "\n",
        "print(\"‚úÖ Processing function defined\\n\")"
      ],
      "metadata": {
        "id": "pIwXh_TDSW2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Processing"
      ],
      "metadata": {
        "id": "6DFeMGMOSY68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìπ VIDEO SOURCE OPTIONS\")\n",
        "print(\"=\"*60)\n",
        "print(\"Sample Videos Available:\")\n",
        "print(\"  1. MOT17-04 - Crowded street (pedestrians) ‚≠ê RECOMMENDED\")\n",
        "print(\"  2. MOT17-02 - Shopping area (pedestrians)\")\n",
        "print(\"  3. MOT17-11 - Highway (cars + people)\")\n",
        "print(\"  4. Upload your own video\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from google.colab import files\n",
        "import urllib.request\n",
        "\n",
        "SAMPLE_VIDEOS = {\n",
        "    '1': {\n",
        "        'name': 'MOT17-04',\n",
        "        'url': 'https://motchallenge.net/sequenceVideos/MOT17-04-DPM-raw.mp4',\n",
        "        'description': 'Crowded street - many pedestrians',\n",
        "        'filename': 'MOT17-04-sample.mp4'\n",
        "    },\n",
        "    '2': {\n",
        "        'name': 'MOT17-02',\n",
        "        'url': 'https://motchallenge.net/sequenceVideos/MOT17-02-DPM-raw.mp4',\n",
        "        'description': 'Shopping area - indoor pedestrians',\n",
        "        'filename': 'MOT17-02-sample.mp4'\n",
        "    },\n",
        "    '3': {\n",
        "        'name': 'MOT17-11',\n",
        "        'url': 'https://motchallenge.net/sequenceVideos/MOT17-11-DPM-raw.mp4',\n",
        "        'description': 'Highway - vehicles and people',\n",
        "        'filename': 'MOT17-11-sample.mp4'\n",
        "    }\n",
        "}\n",
        "\n",
        "choice = input(\"\\nEnter your choice (1-4): \").strip()\n",
        "input_video = None\n",
        "\n",
        "if choice in ['1', '2', '3']:\n",
        "    video_info = SAMPLE_VIDEOS[choice]\n",
        "    print(f\"\\nüì• Downloading {video_info['name']}...\")\n",
        "    print(f\"   Description: {video_info['description']}\")\n",
        "\n",
        "    try:\n",
        "        def download_progress(block_num, block_size, total_size):\n",
        "            downloaded = block_num * block_size\n",
        "            if total_size > 0:\n",
        "                percent = min(downloaded * 100 / total_size, 100)\n",
        "                print(f\"\\r   Progress: {percent:.1f}%\", end='')\n",
        "\n",
        "        urllib.request.urlretrieve(\n",
        "            video_info['url'],\n",
        "            video_info['filename'],\n",
        "            download_progress\n",
        "        )\n",
        "        print(\"\\n‚úÖ Download complete!\")\n",
        "        input_video = video_info['filename']\n",
        "        print(f\"   File: {input_video}\")\n",
        "        print(f\"   Source: MOT Challenge Dataset\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Download failed: {e}\")\n",
        "        print(\"   Please choose option 4 to upload your own video\")\n",
        "        choice = '4'\n",
        "\n",
        "if choice == '4' or input_video is None:\n",
        "    print(\"\\nüì§ UPLOAD YOUR VIDEO\")\n",
        "    print(\"-\" * 60)\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        input_video = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ Video uploaded: {input_video}\")\n",
        "    else:\n",
        "        print(\"‚ùå No video provided\")\n",
        "\n",
        "# Process\n",
        "if input_video and os.path.exists(input_video):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üöÄ STARTING PROCESSING\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    output_video = process_video(\n",
        "        input_video,\n",
        "        output_path='output/tracked_output.mp4',\n",
        "        conf_threshold=0.4,\n",
        "        max_frames=300,\n",
        "        show_predictions=True\n",
        "    )\n",
        "\n",
        "    if output_video:\n",
        "        print(\"\\nüì• Downloading result...\")\n",
        "        files.download(output_video)\n",
        "        print(\"‚úÖ Done! Your tracked video is ready!\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üí° TIPS:\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"‚Ä¢ Full video: Set max_frames=None\")\n",
        "        print(\"‚Ä¢ Faster: Increase conf_threshold to 0.6\")\n",
        "        print(\"‚Ä¢ More detections: Decrease conf_threshold to 0.3\")\n",
        "        print(\"‚Ä¢ MOT17 videos are ~750 frames at 30 FPS\")\n",
        "        print(\"=\"*60)\n",
        "else:\n",
        "    print(\"\\n‚ùå No video to process\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ ALL DONE!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "rh4rPJrTSeWX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}